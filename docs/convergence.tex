\documentclass[11pt]{article}

\usepackage{amsmath, amsfonts, amsthm, amssymb, mathtools}
\usepackage{authblk, color, bm, graphicx, epstopdf, url}
\usepackage[font = small, labelfont = bf, labelsep = period]{caption}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{enumitem,hyperref}
\usepackage{accents}
\newcommand{\ubar}[1]{\underaccent{\bar}{#1}}

\usepackage{booktabs, tabularx, multirow}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\newcolumntype{R}{>{\raggedleft\arraybackslash}X}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}

\newtheorem{prop}{Proposition}
\newtheorem{obs}{Observation}
\newtheorem{rem}{Remark}
\newtheorem{ques}{Question}

\newcommand{\comment}[1]{{\color{red}#1}}
\newcommand{\Image}[1]{\mathop{\text{Im}}\left(#1\right)}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}

\usepackage{fullpage}[2cm]
\linespread{1.5}

\title{Jacobi decomposition of the proximal augmented lagrangian}
\author{Anirudh Subramanyam, Youngdae Kim, Mihai Anitescu}
\date{\today}

\begin{document}
\maketitle

\section{Formulation}
We are interested in solving the following problem.
\begin{equation}\label{eq:nlp}
\begin{array}{r@{\;\;}l}
\displaystyle\mathop{\text{minimize}}_{x_1, \ldots, x_N} & \displaystyle \sum_{i = 1}^N f_i(x_i) \\
\text{subject to} & \displaystyle x_i \in \mathbb{R}^{n_i}, \;\; i \in [N] \coloneqq \{1, \ldots, N\}, \\
& \displaystyle h_i(x_i) = 0, \;\; i \in [N] \\
& \displaystyle \sum_{i = 1}^N A_i x_i = b
\end{array}
\end{equation}
where $A_i \in \mathbb{R}^{m \times n_i}$, $f_i: \mathbb{R}^{n_i} \mapsto \mathbb{R}$ and $h_i :\mathbb{R}^{n_i} \mapsto \mathbb{R}^{c_i}$. %For convenience, we denote by $x$ to mean all the decision variables $(x_1, \ldots, x_N)$.

\subsection{Assumptions}
\begin{enumerate}
    \item\label{assume:feasible}
    Problem~\eqref{eq:nlp} is feasible and bounded.
    \item\label{assume:differentiable}
    All functions $f_i$ and $h_i$ are continuously differentiable. 
    \item\label{assume:lipschitz}
    $\nabla f_i$ and $\nabla h_i$ are Lipschitz continuous with constant $L$.
    \item\label{assume:bounded}
    $\nabla f_i$ and $\nabla h_i$ are uniformly bounded with bound $B$.
    \item\label{assume:licq}
    Let $C_i = (\nabla h_i)^\top : \mathbb{R}^{n_i} \mapsto \mathbb{R}^{c_i \times n_i}$ denote the constraint Jacobian. We assume $C_i$ has full rank for all $x_i \in \mathbb{R}^{n_i}$. \comment{Can we relax this?}
    \item\label{assume:coupling}
    There exists an index $\in [N]$ (w.l.o.g, let this be the last index $N$) such that the linear system (in variables $v$), $A_N \cdot v = b - \sum_{i = 1}^{N-1} A_i y_i$ is always solvable for any $y_i$. In other words, $b - \sum_{i = 1}^{N-1} A_i y_i \in \Image{A_N}$ for all $y_i \in \mathbb{R}^{n_i}$,  $i = 1, \ldots, N-1$. \comment{Can we relax this?}
\end{enumerate}

\section{Algorithm}
Choose values for the following parameters.
\begin{itemize}
    \item $\rho > 0$: the augmented Lagrangian coefficient
    \item $w_1, \ldots, w_N > 0$: the proximal coefficients
    \item $x^0$: initial guess (must be feasible. \comment{Can we relax this?})
    \item $\lambda^0 \in \mathbb{R}^{m}$: initial guess for the dual variable corresponding to $\sum_{i = 1}^N A_i x_i = b$.
\end{itemize}

The algorithm works as follows. Set $k = 0$.
\begin{enumerate}
    \item For $i = 1, \ldots, N$: compute a local solution $x_i^k$ of the following problem.
    \begin{equation}\label{eq:primalstep}
    \begin{array}{r@{\;\;}l}
    \displaystyle\mathop{\text{minimize}}_{x_i} & \displaystyle f_i(x_i) + (\lambda^{k-1})^\top \left[ A_ix_i + \sum_{j \neq i}^N A_j x_j^{k-1} - b\right] + \frac{\rho}{2} \norm{A_ix_i + \sum_{j \neq i}^N A_j x_j^{k-1} - b}^2 \\
    \text{subject to} & \displaystyle  h_i(x_i) = 0.
    \end{array}
    \end{equation}
    
    \item Set 
    \begin{equation}\label{eq:dualstep}
    \lambda^k = \lambda^{k - 1} + \rho \left[\sum_{i = 1}^N A_i x_i^k - b\right]
    \end{equation}
    Set $k = k + 1$ and to step~1.
\end{enumerate}

\section{Convergence analysis}
Before we make our claim, observe that under Assumption~\ref{assume:licq}, all local solutions $x$ of~\eqref{eq:nlp} satisfy the KKT conditions: there exist $\mu_i \in \mathbb{R}^{c_i}$ and $\lambda \in \mathbb{R}^m$ such that the following holds.
\begin{subequations}\label{eq:kkt_nlp}
\begin{align}
& h_i(x_i) = 0, \;\; i \in [N] \label{eq:kkt_nlp:primalfeas}\\
& \sum_{i = 1}^N A_i x_i = b \label{eq:kkt_nlp:coupling}\\
& \nabla f_i(x_i) + C_i(x_i)^\top \mu_i + A_i^\top \lambda = 0, \;\; i \in [N]\label{eq:kkt_nlp:dualfeas}
\end{align}
\end{subequations}
Equation~\eqref{eq:kkt_nlp:primalfeas} is always satisfied by the solutions generated by the Algorithm. The following proposition claims that the other two equations are also satisfied, albeit in the limit $k \to \infty$.

\begin{prop}
    Let $(x^k, \lambda^k)$ be the sequence of solutions generated by the Algorithm. Let $\mu^k$ be the Lagrange multipliers corresponding to $h_i(x_i) = 0$ in Step~1 of the Algorithm. Then, we have
    \begin{subequations}\label{eq:kkt_lim}
        \begin{align}
        & \lim_{k \to \infty} \norm{\sum_{i = 1}^N A_i x_i^k - b} = 0 \label{eq:kkt_lim:coupling}\\
        & \lim_{k \to \infty} \norm{\nabla f_i(x_i^k) + C_i(x_i^k)^\top \mu_i^k + A_i^\top \lambda^k} = 0\label{eq:kkt_lim:dualfeas}
        \end{align}
    \end{subequations}
\end{prop}


\section{Proof sketch}
By Assumption~\eqref{assume:licq}, $x_i^k$ generated in Step~1 must satisfy the KKT conditions:
\begin{equation*}
\nabla f_i(x_i^k) + C_i(x_i^k)^\top \mu_i^k + A_i^\top \lambda^{k - 1} + \rho A_i^\top \left[ A_ix_i^k + \sum_{j \neq i}^N A_j x_j^{k-1} - b\right] + w_i [x_i^k - x_i^{k-1}] = 0.
\end{equation*}
Substitute~\eqref{eq:dualstep} in the above. We get:
\begin{equation}\label{eq:kkt_primalstep}
\nabla f_i(x_i^k) + C_i(x_i^k)^\top \mu_i^k + A_i^\top \lambda^k \underset{\text{\normalsize $\coloneqq R_i^k$}}{\underbrace{- \rho A_i^\top \sum_{j \neq i}^N A_j (x_j^k - x_j^{k - 1}) + w_i(x_i^k - x_i^{k-1})}} = 0.
\end{equation}

Observe that, if we can ensure $\norm{R_i^k} \to 0$, then we will satisfy condition~\eqref{eq:kkt_lim:dualfeas}.
Denote $\Delta x_i^k \coloneqq x_i^k - x_i^{k - 1}$ for all $i$ and $k$. Then, observe that the triangle inequality implies 
\begin{equation*}
\norm{R_i^k}^2 \leq  \sum_{j \neq i}^N \rho \norm{A_i^\top A_j}^2 \norm{\Delta x_j^k}^2 + w_i\norm{\Delta x_i^k}^2
\end{equation*}
Therefore, our goal will be to try and show that $\Delta x_i^k \to 0$ as $k \to \infty$.

Similarly, if we can ensure $\norm{\Delta \lambda^k} \to 0$, where $\Delta \lambda^k \coloneqq \lambda^k - \lambda^{k-1} = \rho \left[\sum_{i = 1}^N A_i x_i^k - b\right]$ (from Step~2 of the algorithm), then we will satisfy condition~\eqref{eq:kkt_lim:coupling}. We reduce this condition to be equivalent to $\Delta x_i^k \to 0$. To see why this is the case, we reason as follows.
First, assume that $\Delta x_i^k \neq 0$ (otherwise the condition is already satisfied).
Then, under Assumption~\ref{assume:coupling}, we have:
\begin{align*}
\Delta \lambda^k \in \Image{A_N} &\implies A_N^\top \Delta \lambda^k \neq 0 \\
&\implies \norm{A_N^\top \Delta \lambda^k} \geq \sigma^{+}_{\text{min}}(A_N^\top) \norm{\Delta \lambda^k} \coloneqq S^{-1} \norm{\Delta \lambda^k} \\
&\implies \norm{\Delta \lambda^k} \leq S \norm{A_N^\top \Delta \lambda^k}.
\end{align*}
where $\sigma^{+}_{\text{min}}(A_N^\top)$ denotes the smallest positive singular value of $A_N^\top$.
Next, we can use~\eqref{eq:kkt_primalstep} and Assumption~\eqref{assume:lipschitz} to relate $\norm{A_N^\top \Delta \lambda^k}$ to $\norm{\Delta x_i^k}$.
\end{document}